{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as pl\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config for training\n",
    "\n",
    "defining variables pertaining to how many layers are going to be in the model, what kind of layers, how many batches, in and out features and other details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 18 # best 11-12\n",
    "learning_rate = 0.0005\n",
    "\n",
    "conv1_kernels = 128\n",
    "conv2_kernels = 96\n",
    "\n",
    "conv1_filter_size = 2\n",
    "conv2_filter_size = 2\n",
    "\n",
    "# in_features=1152\n",
    "input_channels = 18 # like color channels\n",
    "h1 = 1536#1624\n",
    "h2 = 960#1624\n",
    "h3 = 400#200\n",
    "out_features = 64\n",
    "\n",
    "batch_size = 512 # batch is about 0.5% of whole dataset, so each step will be 1/200 of an epoch\n",
    "\n",
    "logging_name = 'CNN1'\n",
    "version_tb = f'cnn1_c{conv1_kernels}_c{conv2_kernels}_h{h1}_h{h2}_h{h3}_e{max_epochs}'\n",
    "\n",
    "project = \"chess CNN model 2\"\n",
    "architecture = \"Convolutional network, 1 label, 128, 128, 2size filter\",\n",
    "dataset = \"max rapid games\","
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([134152, 18, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "data_training = torch.load('tensor_data/nn1_rapid_games_data_training_09_02_24.pt')\n",
    "data_training = data_training.view(data_training.shape[0], 18, 8, 8)\n",
    "print(data_training.shape)\n",
    "# data_training.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_testing = torch.load('tensor_data/nn1_rapid_games_data_testing_09_02_24.pt')\n",
    "data_testing = data_testing.view(data_testing.shape[0], 18, 8, 8)\n",
    "# print(data_testing.shape)\n",
    "# data_testing.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([134152])\n"
     ]
    }
   ],
   "source": [
    "lables_training = torch.load('tensor_data/nn1_rapid_games_lables_training_09_02_24.pt')\n",
    "print(lables_training.shape)\n",
    "# lables_training.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33538])\n"
     ]
    }
   ],
   "source": [
    "lables_testing = torch.load('tensor_data/nn1_rapid_games_lables_testing_09_02_24.pt')\n",
    "print(lables_testing.shape)\n",
    "# lables_testing.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting 64 bit tensors to 32 bit (float functions) and integer numbers (long) for lebel data\n",
    "data_training = data_training.float()\n",
    "data_testing = data_testing.float()\n",
    "lables_training = lables_training.long()\n",
    "lables_testing = lables_testing.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6516b6fcf0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up a seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a torch dataset object out of the data\n",
    "training_dataset = TensorDataset(data_training, lables_training)\n",
    "testing_dataset = TensorDataset(data_testing, lables_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a dataloader object out of dataset object (which properly loads data in batches)\n",
    "data_loader_training = DataLoader(training_dataset, batch_size=batch_size, shuffle=True, num_workers=7)\n",
    "data_loader_testing = DataLoader(testing_dataset, batch_size=batch_size, num_workers=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Defining a convolutional neural network model with 2 convolutional layers and 3 linear, fully connected layers.\n",
    "\n",
    "I'm using Lightning module which inherits from nn module. I'm logging accuracy and loss using the Torchmetrics accuracy function and Lightning log function.\n",
    "\n",
    "I implement training and validation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, input_channels=input_channels, h1=h1, h2=h2, h3=h3, out_features=64): #out = 64 squares to move to \n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(input_channels, conv1_kernels, conv1_filter_size, 1, padding='same')\n",
    "\n",
    "        self.conv2 = nn.Conv2d(conv1_kernels, conv2_kernels, conv2_filter_size, 1, padding='same')\n",
    "\n",
    "        # self.fc1 = nn.Linear(8*8*conv1_kernels, l1)\n",
    "        # self.fc2 = nn.Linear(l1, l2)\n",
    "        # self.fc3 = nn.Linear(l2, l3)\n",
    "        # self.fc3 = nn.Linear(h2, h3)\n",
    "        # self.fc3 = nn.Linear(h2, h3)\n",
    "        # self.fc1 = nn.Linear(8192, 60)\n",
    "\n",
    "        self.fc1 = nn.Linear(8*8*conv2_kernels, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.fc3 = nn.Linear(h2, h3)\n",
    "        # self.fc3 = nn.Linear(h2, h3)\n",
    "\n",
    "\n",
    "        self.out = nn.Linear(h3, out_features)\n",
    "        self.accuracy = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "\n",
    "        x = x.view(-1, 8*8*conv2_kernels)\n",
    "        # x = x.view(-1,1152)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_index):\n",
    "\n",
    "        x, y = batch\n",
    "        preds = self.forward(x) # since we run itself\n",
    "        # print(preds)\n",
    "        loss = F.cross_entropy(preds, y)\n",
    "        \n",
    "        accuracy = self.accuracy(preds, y)\n",
    "        # self.log('train_acc_step', self.accuracy)\n",
    "        self.log('loss', loss)\n",
    "        self.log('accuracy', accuracy)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_index):\n",
    "\n",
    "        x, y = batch\n",
    "        preds = self.forward(x) # since we run itself\n",
    "        loss = F.cross_entropy(preds, y)\n",
    "        accuracy = self.accuracy(preds, y)\n",
    "        \n",
    "        # self.log('train_acc_step', self.accuracy)\n",
    "        self.log('loss validation', loss)\n",
    "        self.log('accuracy validation', accuracy)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        return torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a Tensorboard logger object\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=logging_name, version = version_tb) #tb logs is a directory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type               | Params\n",
      "------------------------------------------------\n",
      "0 | conv1    | Conv2d             | 9.3 K \n",
      "1 | conv2    | Conv2d             | 49.2 K\n",
      "2 | fc1      | Linear             | 9.4 M \n",
      "3 | fc2      | Linear             | 1.5 M \n",
      "4 | fc3      | Linear             | 384 K \n",
      "5 | out      | Linear             | 25.7 K\n",
      "6 | accuracy | MulticlassAccuracy | 0     \n",
      "------------------------------------------------\n",
      "11.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.4 M    Total params\n",
      "45.532    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maru/miniforge3/envs/torch_chess/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1705951428005/work/aten/src/ATen/native/Convolution.cpp:1008.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  42%|████▏     | 111/263 [00:03<00:04, 36.48it/s, v_num=_e18]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 263/263 [00:07<00:00, 32.98it/s, v_num=_e18]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=18` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 263/263 [00:08<00:00, 31.41it/s, v_num=_e18]\n"
     ]
    }
   ],
   "source": [
    "# defining Trainer object and doing actual training.\n",
    "# setting precision as 16-mixed which may speed up training (as opposed to 64 or 32 bit)\n",
    "trainer = pl.Trainer(max_epochs=max_epochs, logger=logger, precision='16-mixed')\n",
    "\n",
    "trainer.fit(model, data_loader_training, data_loader_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model to a file for future use\n",
    "I've saved it earlier in training when the accuracy and loss for validation data were optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), f'models/nn1_model_ck1{conv1_kernels}_ck2{conv2_kernels}_fc1{h1}_fc2{h2}_e_{max_epochs}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'models/cnn1_ck1{conv1_kernels}_ck2{conv2_kernels}_l{h1}_l{h2}_l{h3}_e{max_epochs}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(Cnn, f'model_definitions/nn1_model_def_ck1{conv1_kernels}_ck2{conv2_kernels}_fc1{l1}_fc2{l2}_e_{epochs}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'models/nn1_model_cnn_128_128_1624_1624_100_batches.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'models/nn1_model_linear_900_900.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_chess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
